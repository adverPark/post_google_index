"""
CSV íŒŒì¼ ê´€ë¦¬ ëª¨ë“ˆ

ì´ ëª¨ë“ˆì€ ë¸”ë¡œê·¸ URLì˜ ì¸ë±ì‹± ìƒíƒœë¥¼ CSV íŒŒì¼ë¡œ ê´€ë¦¬í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
ê° URLì˜ ìƒíƒœ(PENDING/SUCCESS/FAILED)ì™€ ë‚ ì§œ ì •ë³´ë¥¼ ì¶”ì í•©ë‹ˆë‹¤.
"""

import csv
import os
from datetime import datetime
from typing import List, Dict, Optional
from pathlib import Path


# CSV íŒŒì¼ í•„ë“œëª… ì •ì˜
CSV_HEADERS = ['url', 'status', 'lastmod', 'created_at', 'updated_at', 'retry_count']

# ìƒíƒœ ê°’ ì •ì˜
STATUS_PENDING = 'PENDING'  # ì¸ë±ì‹± ëŒ€ê¸° ì¤‘
STATUS_SUCCESS = 'SUCCESS'  # ì¸ë±ì‹± ì„±ê³µ
STATUS_FAILED = 'FAILED'    # ì¸ë±ì‹± ì‹¤íŒ¨ (3íšŒ ì¬ì‹œë„ í›„)


def ensure_data_directory(csv_path: str) -> None:
    """
    CSV íŒŒì¼ì´ ì €ì¥ë  ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³ ,
    ì—†ìœ¼ë©´ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        csv_path: CSV íŒŒì¼ ê²½ë¡œ

    Note:
        ì˜ˆ: csv_pathê°€ 'data/urls.csv'ì´ë©´ 'data' í´ë”ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    directory = os.path.dirname(csv_path)
    if directory and not os.path.exists(directory):
        os.makedirs(directory, exist_ok=True)
        print(f"ğŸ“ ë””ë ‰í† ë¦¬ ìƒì„±: {directory}")


def read_csv(csv_path: str) -> List[Dict[str, str]]:
    """
    CSV íŒŒì¼ì„ ì½ì–´ì„œ URL ì •ë³´ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.

    Args:
        csv_path: CSV íŒŒì¼ ê²½ë¡œ

    Returns:
        URL ì •ë³´ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
        [{'url': 'URL', 'status': 'ìƒíƒœ', 'lastmod': 'ë‚ ì§œ', ...}, ...]

    Note:
        - íŒŒì¼ì´ ì—†ëŠ” ê²½ìš° ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤
        - CSV ì¸ì½”ë”©ì€ UTF-8ì„ ì‚¬ìš©í•©ë‹ˆë‹¤
    """
    # íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    if not os.path.exists(csv_path):
        print(f"â„¹ï¸  CSV íŒŒì¼ ì—†ìŒ: {csv_path}")
        return []

    try:
        with open(csv_path, 'r', encoding='utf-8', newline='') as f:
            # DictReaderë¥¼ ì‚¬ìš©í•˜ì—¬ ê° í–‰ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ì½ê¸°
            reader = csv.DictReader(f)
            data = list(reader)
            print(f"ğŸ“– CSV íŒŒì¼ ì½ê¸° ì™„ë£Œ: {len(data)}ê°œ í•­ëª©")
            return data

    except Exception as e:
        print(f"âŒ CSV íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {csv_path}")
        print(f"   ì—ëŸ¬: {str(e)}")
        return []


def write_csv(csv_path: str, data: List[Dict[str, str]]) -> bool:
    """
    URL ì •ë³´ ë¦¬ìŠ¤íŠ¸ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.

    Args:
        csv_path: CSV íŒŒì¼ ê²½ë¡œ
        data: URL ì •ë³´ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸

    Returns:
        True: ì €ì¥ ì„±ê³µ
        False: ì €ì¥ ì‹¤íŒ¨

    Note:
        - ê¸°ì¡´ íŒŒì¼ì´ ìˆìœ¼ë©´ ë®ì–´ì”ë‹ˆë‹¤
        - í—¤ë”(url, status, lastmod, ...)ëŠ” ìë™ìœ¼ë¡œ ì¶”ê°€ë©ë‹ˆë‹¤
    """
    try:
        # ë””ë ‰í† ë¦¬ ìƒì„± í™•ì¸
        ensure_data_directory(csv_path)

        # CSV íŒŒì¼ ì“°ê¸°
        with open(csv_path, 'w', encoding='utf-8', newline='') as f:
            writer = csv.DictWriter(f, fieldnames=CSV_HEADERS)

            # í—¤ë” ì‘ì„±
            writer.writeheader()

            # ë°ì´í„° ì‘ì„±
            writer.writerows(data)

        print(f"ğŸ’¾ CSV íŒŒì¼ ì €ì¥ ì™„ë£Œ: {len(data)}ê°œ í•­ëª©")
        return True

    except Exception as e:
        print(f"âŒ CSV íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {csv_path}")
        print(f"   ì—ëŸ¬: {str(e)}")
        return False


def get_url_status(csv_path: str, url: str) -> Optional[str]:
    """
    íŠ¹ì • URLì˜ í˜„ì¬ ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤.

    Args:
        csv_path: CSV íŒŒì¼ ê²½ë¡œ
        url: í™•ì¸í•  URL

    Returns:
        ìƒíƒœ ê°’ (PENDING/SUCCESS/FAILED) ë˜ëŠ” None (URLì´ ì—†ëŠ” ê²½ìš°)

    Example:
        status = get_url_status('data/urls.csv', 'https://blog.tistory.com/123')
        if status == 'PENDING':
            print("ì¸ë±ì‹± ëŒ€ê¸° ì¤‘")
    """
    data = read_csv(csv_path)

    # URLì´ ì¼ì¹˜í•˜ëŠ” í•­ëª© ì°¾ê¸°
    for row in data:
        if row['url'] == url:
            return row.get('status')

    # URLì„ ì°¾ì§€ ëª»í•œ ê²½ìš°
    return None


def add_url(csv_path: str, url: str, lastmod: str = '') -> bool:
    """
    ìƒˆë¡œìš´ URLì„ CSVì— ì¶”ê°€í•©ë‹ˆë‹¤.
    ì´ë¯¸ ì¡´ì¬í•˜ëŠ” URLì¸ ê²½ìš° ì¶”ê°€í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

    Args:
        csv_path: CSV íŒŒì¼ ê²½ë¡œ
        url: ì¶”ê°€í•  URL
        lastmod: ë§ˆì§€ë§‰ ìˆ˜ì •ì¼ (ì„ íƒ)

    Returns:
        True: ì¶”ê°€ ì„±ê³µ
        False: ì´ë¯¸ ì¡´ì¬í•˜ê±°ë‚˜ ì¶”ê°€ ì‹¤íŒ¨

    Note:
        - ìƒˆë¡œ ì¶”ê°€ëœ URLì˜ ì´ˆê¸° ìƒíƒœëŠ” PENDINGì…ë‹ˆë‹¤
        - created_atê³¼ updated_atì€ í˜„ì¬ ì‹œê°„ìœ¼ë¡œ ìë™ ì„¤ì •ë©ë‹ˆë‹¤
        - retry_countëŠ” 0ìœ¼ë¡œ ì´ˆê¸°í™”ë©ë‹ˆë‹¤
    """
    data = read_csv(csv_path)

    # ì´ë¯¸ ì¡´ì¬í•˜ëŠ” URLì¸ì§€ í™•ì¸
    for row in data:
        if row['url'] == url:
            print(f"â„¹ï¸  ì´ë¯¸ ì¡´ì¬í•˜ëŠ” URL: {url}")
            return False

    # í˜„ì¬ ì‹œê°„ (ISO 8601 í˜•ì‹)
    now = datetime.now().isoformat()

    # ìƒˆ URL ì •ë³´ ì¶”ê°€
    new_row = {
        'url': url,
        'status': STATUS_PENDING,      # ì´ˆê¸° ìƒíƒœëŠ” PENDING
        'lastmod': lastmod,
        'created_at': now,
        'updated_at': now,
        'retry_count': '0'             # ì¬ì‹œë„ íšŸìˆ˜ 0ìœ¼ë¡œ ì´ˆê¸°í™”
    }

    data.append(new_row)

    # CSV íŒŒì¼ ì €ì¥
    return write_csv(csv_path, data)


def update_url_status(csv_path: str, url: str, status: str, increment_retry: bool = False) -> bool:
    """
    íŠ¹ì • URLì˜ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.

    Args:
        csv_path: CSV íŒŒì¼ ê²½ë¡œ
        url: ì—…ë°ì´íŠ¸í•  URL
        status: ìƒˆë¡œìš´ ìƒíƒœ (PENDING/SUCCESS/FAILED)
        increment_retry: Trueì´ë©´ ì¬ì‹œë„ íšŸìˆ˜ë¥¼ 1 ì¦ê°€ì‹œí‚´

    Returns:
        True: ì—…ë°ì´íŠ¸ ì„±ê³µ
        False: URLì„ ì°¾ì§€ ëª»í–ˆê±°ë‚˜ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨

    Note:
        - updated_atì€ í˜„ì¬ ì‹œê°„ìœ¼ë¡œ ìë™ ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤
        - increment_retry=Trueì¸ ê²½ìš° retry_countê°€ ì¦ê°€í•©ë‹ˆë‹¤
    """
    data = read_csv(csv_path)

    # URLì´ ì¼ì¹˜í•˜ëŠ” í•­ëª© ì°¾ì•„ì„œ ì—…ë°ì´íŠ¸
    updated = False
    for row in data:
        if row['url'] == url:
            # ìƒíƒœ ì—…ë°ì´íŠ¸
            row['status'] = status
            row['updated_at'] = datetime.now().isoformat()

            # ì¬ì‹œë„ íšŸìˆ˜ ì¦ê°€ (ì˜µì…˜)
            if increment_retry:
                current_retry = int(row.get('retry_count', 0))
                row['retry_count'] = str(current_retry + 1)

            updated = True
            break

    if not updated:
        print(f"âŒ URLì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {url}")
        return False

    # CSV íŒŒì¼ ì €ì¥
    return write_csv(csv_path, data)


def get_pending_urls(csv_path: str, limit: Optional[int] = None) -> List[Dict[str, str]]:
    """
    PENDING ìƒíƒœì¸ URL ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.

    Args:
        csv_path: CSV íŒŒì¼ ê²½ë¡œ
        limit: ìµœëŒ€ ë°˜í™˜ ê°œìˆ˜ (Noneì´ë©´ ì „ì²´)

    Returns:
        PENDING ìƒíƒœ URL ì •ë³´ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸

    Note:
        - Google Indexing APIëŠ” ì¼ì¼ 200ê°œ ì œí•œì´ ìˆìœ¼ë¯€ë¡œ
          limit=200ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤
    """
    data = read_csv(csv_path)

    # PENDING ìƒíƒœì¸ í•­ëª©ë§Œ í•„í„°ë§
    pending = [row for row in data if row.get('status') == STATUS_PENDING]

    # limitì´ ì§€ì •ëœ ê²½ìš° í•´ë‹¹ ê°œìˆ˜ë§Œ ë°˜í™˜
    if limit is not None:
        pending = pending[:limit]

    print(f"ğŸ“‹ PENDING ìƒíƒœ URL: {len(pending)}ê°œ")
    return pending


def add_urls_batch(csv_path: str, urls: List[Dict[str, str]]) -> int:
    """
    ì—¬ëŸ¬ URLì„ í•œ ë²ˆì— CSVì— ì¶”ê°€í•©ë‹ˆë‹¤.
    ì‚¬ì´íŠ¸ë§µì—ì„œ ì¶”ì¶œí•œ URL ëª©ë¡ì„ ì´ˆê¸°í™”í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.

    Args:
        csv_path: CSV íŒŒì¼ ê²½ë¡œ
        urls: URL ì •ë³´ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
              [{'loc': 'URL', 'lastmod': 'ë‚ ì§œ'}, ...]

    Returns:
        ì¶”ê°€ëœ URL ê°œìˆ˜

    Note:
        - ì´ë¯¸ ì¡´ì¬í•˜ëŠ” URLì€ ê±´ë„ˆëœë‹ˆë‹¤
        - ìƒˆë¡œ ì¶”ê°€ëœ URLì˜ ì´ˆê¸° ìƒíƒœëŠ” PENDINGì…ë‹ˆë‹¤
    """
    data = read_csv(csv_path)

    # ê¸°ì¡´ URL ëª©ë¡ (ì¤‘ë³µ ì²´í¬ìš©)
    existing_urls = {row['url'] for row in data}

    # í˜„ì¬ ì‹œê°„
    now = datetime.now().isoformat()

    # ì¶”ê°€ëœ ê°œìˆ˜ ì¹´ìš´í„°
    added_count = 0

    # ê° URL ì²˜ë¦¬
    for url_info in urls:
        url = url_info.get('loc', '')
        lastmod = url_info.get('lastmod', '')

        # ë¹ˆ URLì´ê±°ë‚˜ ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ê²½ìš° ê±´ë„ˆë›°ê¸°
        if not url or url in existing_urls:
            continue

        # ìƒˆ URL ì •ë³´ ì¶”ê°€
        new_row = {
            'url': url,
            'status': STATUS_PENDING,
            'lastmod': lastmod,
            'created_at': now,
            'updated_at': now,
            'retry_count': '0'
        }

        data.append(new_row)
        existing_urls.add(url)  # ì¤‘ë³µ ì²´í¬ ì„¸íŠ¸ì— ì¶”ê°€
        added_count += 1

    # CSV íŒŒì¼ ì €ì¥
    if added_count > 0:
        write_csv(csv_path, data)
        print(f"âœ… {added_count}ê°œ URL ì¶”ê°€ ì™„ë£Œ")
    else:
        print(f"â„¹ï¸  ìƒˆë¡œ ì¶”ê°€í•  URL ì—†ìŒ (ëª¨ë‘ ê¸°ì¡´ URL)")

    return added_count


def get_statistics(csv_path: str) -> Dict[str, int]:
    """
    CSV íŒŒì¼ì˜ í†µê³„ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

    Args:
        csv_path: CSV íŒŒì¼ ê²½ë¡œ

    Returns:
        í†µê³„ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        {
            'total': ì „ì²´ URL ê°œìˆ˜,
            'pending': PENDING ê°œìˆ˜,
            'success': SUCCESS ê°œìˆ˜,
            'failed': FAILED ê°œìˆ˜
        }

    Example:
        stats = get_statistics('data/urls.csv')
        print(f"ì „ì²´: {stats['total']}, ì„±ê³µ: {stats['success']}")
    """
    data = read_csv(csv_path)

    # ìƒíƒœë³„ ê°œìˆ˜ ê³„ì‚°
    stats = {
        'total': len(data),
        'pending': 0,
        'success': 0,
        'failed': 0
    }

    for row in data:
        status = row.get('status', '')
        if status == STATUS_PENDING:
            stats['pending'] += 1
        elif status == STATUS_SUCCESS:
            stats['success'] += 1
        elif status == STATUS_FAILED:
            stats['failed'] += 1

    return stats
